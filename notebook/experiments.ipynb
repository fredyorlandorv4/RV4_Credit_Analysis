{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b929fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/nyamo/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c08b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# User loader for Flask-Login\n",
    "@login_manager.user_loader\n",
    "def load_user(user_id):\n",
    "    return User.query.get(int(user_id))\n",
    "\n",
    "# Initialize database and models on first run\n",
    "with app.app_context():\n",
    "    init_database(app)\n",
    "    \n",
    "    # Load existing models or train new ones\n",
    "    if not model.load_models():\n",
    "        print(\"No existing models found. Training on sample data...\")\n",
    "        DATA_FILE_PATH = 'data/credit_data.csv'\n",
    "        if not os.path.exists(DATA_FILE_PATH):\n",
    "            generate_and_save_data(DATA_FILE_PATH)\n",
    "        df = pd.read_csv(DATA_FILE_PATH)\n",
    "        model.train(df, source='initial_sample')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "REQUIRED_DOCS = ['doc_id', 'doc_salary', 'doc_bank_statement', 'doc_tax_return', 'doc_property_docs']\n",
    "\n",
    "# --- LANGUAGE & CONTEXT ---\n",
    "@app.before_request\n",
    "def before_request():\n",
    "    if 'language' not in session:\n",
    "        session['language'] = 'en'\n",
    "\n",
    "@app.context_processor\n",
    "def inject_get_text():\n",
    "    def get_text(key):\n",
    "        return _get_text(session.get('language', 'en'), key)\n",
    "    return dict(get_text=get_text)\n",
    "\n",
    "@app.route('/change_language/<lang>')\n",
    "def change_language(lang):\n",
    "    if lang in ['en', 'es']:\n",
    "        session['language'] = lang\n",
    "    return redirect(request.referrer or url_for('dashboard'))\n",
    "\n",
    "# --- MAIN ROUTES ---\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Redirect to login or dashboard\"\"\"\n",
    "    if current_user.is_authenticated:\n",
    "        return redirect(url_for('dashboard'))\n",
    "    return redirect(url_for('auth.login'))\n",
    "\n",
    "@app.route('/dashboard')\n",
    "@login_required\n",
    "def dashboard():\n",
    "    \"\"\"Main dashboard with user-specific data and model info\"\"\"\n",
    "    # Get applications for current user (or all if admin)\n",
    "    if current_user.role.value == 'admin':\n",
    "        applications = Application.query.all()\n",
    "    else:\n",
    "        applications = current_user.applications.all()\n",
    "    \n",
    "    # Convert to DataFrame for analysis\n",
    "    if applications and len(applications) > 0:\n",
    "        df_data = []\n",
    "        for app in applications:\n",
    "            df_data.append({\n",
    "                'Application_ID': app.application_id,\n",
    "                'Application_Date': app.application_date or datetime.utcnow(),\n",
    "                'Age': app.age or 35,\n",
    "                'Gender': app.gender or 'Male',\n",
    "                'Monthly_Income': app.monthly_income or 35000,\n",
    "                'Credit_Score': app.credit_score or 650,\n",
    "                'DTI_Ratio': app.dti_ratio or 0.35,\n",
    "                'Employment_Status': app.employment_status or 'Employed',\n",
    "                'Processing_Time_Days': app.processing_time_days or 15,\n",
    "                'Status': app.status or 'In-Process'\n",
    "            })\n",
    "        df_active = pd.DataFrame(df_data)\n",
    "    else:\n",
    "        # Use sample data if no real data exists\n",
    "        try:\n",
    "            df_active = pd.read_csv('data/credit_data.csv')\n",
    "            if 'Application_Date' in df_active.columns:\n",
    "                df_active['Application_Date'] = pd.to_datetime(df_active['Application_Date'])\n",
    "        except:\n",
    "            # Create minimal sample data\n",
    "            df_active = pd.DataFrame({\n",
    "                'Application_ID': ['SAMPLE-001', 'SAMPLE-002', 'SAMPLE-003'],\n",
    "                'Application_Date': [datetime.utcnow() - timedelta(days=i*10) for i in range(3)],\n",
    "                'Age': [35, 42, 28],\n",
    "                'Gender': ['Male', 'Female', 'Male'],\n",
    "                'Monthly_Income': [45000, 62000, 38000],\n",
    "                'Credit_Score': [720, 680, 750],\n",
    "                'DTI_Ratio': [0.32, 0.28, 0.45],\n",
    "                'Employment_Status': ['Employed', 'Employed', 'Self-Employed'],\n",
    "                'Processing_Time_Days': [15, 22, 18],\n",
    "                'Status': ['Approved', 'In-Process', 'Approved']\n",
    "            })\n",
    "    \n",
    "    # Calculate KPIs - Ensure values are calculated properly\n",
    "    total_apps = len(df_active)\n",
    "    approved_count = len(df_active[df_active['Status'] == 'Approved'])\n",
    "    declined_count = len(df_active[df_active['Status'] == 'Declined'])\n",
    "    \n",
    "    kpis = {\n",
    "        'total_apps': f\"{total_apps:,}\",\n",
    "        'approval_rate': f\"{(approved_count / total_apps * 100) if total_apps > 0 else 0:.1f}%\",\n",
    "        'rejection_rate': f\"{(declined_count / total_apps * 100) if total_apps > 0 else 0:.1f}%\",\n",
    "        'avg_processing_time': f\"{df_active['Processing_Time_Days'].mean() if total_apps > 0 else 0:.1f} days\"\n",
    "    }\n",
    "    \n",
    "    # Generate graphs - ensure data exists\n",
    "    graphs = {}\n",
    "    try:\n",
    "        if len(df_active) > 0:\n",
    "            graphs['trends'] = pio.to_json(create_trends_chart(df_active))\n",
    "            graphs['funnel'] = pio.to_json(create_funnel_chart(df_active))\n",
    "            \n",
    "            if len(df_active) > 5:  # Need minimum data for correlation\n",
    "                graphs['heatmap'] = pio.to_json(create_correlation_heatmap(df_active))\n",
    "            else:\n",
    "                graphs['heatmap'] = None\n",
    "                \n",
    "            graphs['box_plot'] = pio.to_json(create_box_plot(df_active))\n",
    "            graphs['sunburst'] = pio.to_json(create_sunburst_chart(df_active))\n",
    "        else:\n",
    "            graphs = {\n",
    "                'trends': None,\n",
    "                'funnel': None,\n",
    "                'heatmap': None,\n",
    "                'box_plot': None,\n",
    "                'sunburst': None\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR generating charts: {str(e)}\")\n",
    "        graphs = {\n",
    "            'trends': None,\n",
    "            'funnel': None,\n",
    "            'heatmap': None,\n",
    "            'box_plot': None,\n",
    "            'sunburst': None\n",
    "        }\n",
    "    \n",
    "    # Get model information\n",
    "    model_info = None\n",
    "    try:\n",
    "        info = model.get_model_info()\n",
    "        if info.get('last_metrics'):\n",
    "            model_info = {\n",
    "                'last_trained': info.get('training_history', [{}])[-1].get('timestamp', 'Never') if info.get('training_history') else 'Never',\n",
    "                'accuracy': round(info['last_metrics'].get('approval', {}).get('accuracy', 0) * 100, 1),\n",
    "                'records_used': info.get('training_history', [{}])[-1].get('records', 0) if info.get('training_history') else 0\n",
    "            }\n",
    "    except Exception as e:\n",
    "        app.logger.warning(f\"Could not load model info: {e}\")\n",
    "    \n",
    "    # Get recent applications for current user\n",
    "    recent_apps = current_user.applications.order_by(Application.application_date.desc()).limit(5).all()\n",
    "    \n",
    "    return render_template('dashboard.html', \n",
    "                         kpis=kpis, \n",
    "                         graphs=graphs, \n",
    "                         recent_apps=recent_apps,\n",
    "                         user=current_user,\n",
    "                         model_info=model_info)\n",
    "\n",
    "@app.route('/my_clients')\n",
    "@login_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfcb17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb7dfae",
   "metadata": {},
   "source": [
    "# Training Data Management\n",
    "\n",
    "## Overview\n",
    "The system now automatically saves all training data used for model training sessions. This ensures data provenance, model reproducibility, and compliance with audit requirements.\n",
    "\n",
    "## Data Storage Strategy\n",
    "\n",
    "### Automatic Data Saving\n",
    "- Every training session saves the complete dataset to `data/` directory\n",
    "- Files are named with format: `training_data_{source}_{timestamp}.csv`\n",
    "- Training history includes references to the specific data files used\n",
    "\n",
    "### File Naming Convention\n",
    "- `training_data_database_20250911_143052.csv` - Database training session\n",
    "- `training_data_csv_20250911_143052.csv` - CSV upload training session  \n",
    "- `training_data_sample_20250911_143052.csv` - Generated data training session\n",
    "\n",
    "### Benefits\n",
    "1. **Reproducibility**: Exact training data can be retrieved for any model version\n",
    "2. **Audit Trail**: Complete record of what data was used for training\n",
    "3. **Data Quality**: Preserved datasets for quality analysis and debugging\n",
    "4. **Compliance**: Meeting regulatory requirements for model documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Accessing Training Data History\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model_pipeline import model\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get model training history\n",
    "history = model.get_model_info()['training_history']\n",
    "\n",
    "print(\"Training History:\")\n",
    "print(\"=\" * 50)\n",
    "for i, session in enumerate(history):\n",
    "    print(f\"Session {i+1}:\")\n",
    "    print(f\"  Timestamp: {session['timestamp']}\")\n",
    "    print(f\"  Source: {session['source']}\")\n",
    "    print(f\"  Records: {session['records']}\")\n",
    "    print(f\"  Data File: {session.get('training_data_file', 'Not saved')}\")\n",
    "    if 'metrics' in session:\n",
    "        print(f\"  Approval Accuracy: {session['metrics']['approval']['accuracy']:.3f}\")\n",
    "        print(f\"  Withdrawal Accuracy: {session['metrics']['withdrawal']['accuracy']:.3f}\")\n",
    "    print()\n",
    "\n",
    "# List all training data files\n",
    "data_dir = '../data'\n",
    "if os.path.exists(data_dir):\n",
    "    training_files = [f for f in os.listdir(data_dir) if f.startswith('training_data_')]\n",
    "    print(f\"Available Training Data Files ({len(training_files)}):\")\n",
    "    print(\"=\" * 50)\n",
    "    for file in sorted(training_files):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        size_mb = os.path.getsize(file_path) / (1024*1024)\n",
    "        print(f\"  {file} ({size_mb:.2f} MB)\")\n",
    "else:\n",
    "    print(\"Data directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Loading and Analyzing Training Data\n",
    "def analyze_training_data(filename):\n",
    "    \"\"\"Analyze a specific training data file\"\"\"\n",
    "    file_path = os.path.join('../data', filename)\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {filename}\")\n",
    "        return\n",
    "    \n",
    "    # Load the data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(f\"Training Data Analysis: {filename}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(f\"Date Range: {df['Application_Date'].min()} to {df['Application_Date'].max()}\")\n",
    "    print()\n",
    "    \n",
    "    # Status distribution\n",
    "    print(\"Status Distribution:\")\n",
    "    status_counts = df['Status'].value_counts()\n",
    "    for status, count in status_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"  {status}: {count} ({percentage:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Key statistics\n",
    "    print(\"Key Statistics:\")\n",
    "    print(f\"  Average Credit Score: {df['Credit_Score'].mean():.0f}\")\n",
    "    print(f\"  Average Monthly Income: Q{df['Monthly_Income'].mean():,.0f}\")\n",
    "    print(f\"  Average DTI Ratio: {df['DTI_Ratio'].mean():.3f}\")\n",
    "    print(f\"  Average Loan Amount: Q{df['Loan_Amount'].mean():,.0f}\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage - replace with actual filename\n",
    "# df = analyze_training_data('training_data_sample_20250911_143052.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
